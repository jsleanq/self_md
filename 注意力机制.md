# 注意力机制

本质：根据输入的重要性自适应地完成特征加权

**区分方式：1.分配权重；2.注意力域**

## 1.分配权重

软注意（全局注意）、硬注意（局部注意）和自注意（内注意）

### Soft/Global Attention(软注意机制)

对每个输入项的分配的权重为0-1之间，也就是某些部分关注的多一点，某些部分关注的少一点，因为对大部分信息都有考虑，但考虑程度不一样，所以相对来说计算量比较大。

### Hard/Local Attention(硬注意机制)

对每个输入项分配的权重非0即1，和软注意不同，硬注意机制只考虑那部分需要关注，哪部分不关注，也就是直接舍弃掉一些不相关项。优势在于可以减少一定的时间和计算成本，但有可能丢失掉一些本应该注意的信息。

### Self/Intra Attention（自注意力机制）

对每个输入项分配的权重取决于输入项之间的相互作用，即通过输入项内部的"表决"来决定应该关注哪些输入项。和前两种相比，在处理很长的输入时，具有并行计算的优势。

## 2.注意力域

### 通道注意力（注意图中有什么）

不同特征映射中的不同通道代表不同的对象，通道注意力重新调整每个通道的权重（**重新选择对象**），从而找到要注意的内容

#### SENet

挤压模块通过全局平均池化收集全局空间信息。

激励模块通过使用全连接层和非线性层（ReLU和sigmoid）捕捉通道关系并输出注意力向量

**优点：**

抑制噪声、强调重要通道

**缺点：**

1.全局平均池化过于简单，不能提取到复杂的全局信息；

2.全连接层加大了模型的复杂程度

#### GSoP-Net

全局二阶池化（GSoP）块在收集全局信息的同时对高阶特征数据建模来改进挤压模块。

激励模块通过使用全连接层和非线性层（ReLU和sigmoid）捕捉通道关系并输出注意力向量

**优点：**

提高了全局信息的搜集能力

**缺点：**

1.增大了额外计算量，一般在多个残差块后增加一个GSoP块；

#### SRM

基于轻量级风格的再校准模块（SRM）

提出了style pooling：

SRM首先通过结合全局平均池和全局标准差池化的风格式池化（SP（·））收集全局信息。然后使用通道全连接（CFC（·））层（即每个通道全连接）、批量归一化BN和sigmoid函数σ来提供注意力向量。最后，与SE块一样，输入特征乘以注意力向量。

<img src="https://img-blog.csdnimg.cn/f6c532d9a6bf409686a0c05a92f6fff7.png#pic_center" alt="在这里插入图片描述" style="zoom:50%;" />

**优点：**

改进了SE模块的挤压与激励模块

![img](https://img-blog.csdnimg.cn/8a60b0e3d94542e49635bac4ea067c1e.png#pic_center)

### 空间注意力（注意关键因素在哪里）

#### Self-attention and variants（自注意力）

自注意力机制实际上是想让机器注意到整个输入中不同部分之间的相关性，虽然考虑了所有的输入向量，但没有考虑到向量的位置信息

CNN卷积神经网络是特殊情况下的一种self-attention（CNN希望模型能够考虑多个像素点，即感受野），self-attention就是复杂版的CNN（自己决定感受野的形状）。

自注意力机制的重点是通过聚合单个样本中所有其他位置的特征来完善每个位置的表示，这导致了样本中位置数量的二次计算复杂性，因此引入变体：

disentangled non-local提高了自注意机制的准确性和有效性

大多数变体侧重于降低其计算复杂性，包括CCNet、EMANet、ANN、GCNet、GloRe、HamNet、GENet、PSANet

##### non-local

易于集成，针对一个feature map进行信息的refine，non-local可以作为一个组件，和其它网络结构结合，经过作者实验，证明了其可以应用于图像分类、目标检测、目标分割、姿态识别等视觉任务中，并且效果有不同程度的提升，Non-local在视频分类上效果很好，在视频分类的任务中效果可观

### 分支通道（注意感受野）

分支注意可以被看作是一种动态的分支选择机制：注意哪个分支，与多分支结构一起使用。

#### Highway networks

自适应选通机制，使信息能够跨层流动，以解决训练非常深层网络的问题。

#### Selective Kernel Networks

允许每个神经元根据输入信息的多个尺度自适应调整其感受野大小。设计了一个称为选择性内核（SK）单元的构造块，其中，多个具有不同内核大小的分支使用softmax注意力进行融合，该注意力由这些分支中的信息引导。对这些分支的不同关注产生了融合层神经元有效感受野的不同大小。多个SK单元堆叠在一个称为选择性内核网络（SKNET）的深层网络中。

#### CondConv

一般情况下增强网络表现力的典型方法是增加其深度或宽度，这会带来大量额外的计算成本。为了更有效地提高卷积神经网络的容量，Yang等人提出了一种新的多分支算子CondConv，可以定义一个普通的卷积（组合多个卷积核）

#### Dynamic Convolution

使用K个大小和输入/输出维度相同的并行卷积核，而不是每层一个核。与SE块一样，它采用挤压和激励机制为不同的卷积核生成注意权重。这些卷积核通过加权求和动态聚合，提高表示能力，并且可以轻松地用作任何卷积的替代品。

### 混合注意力：

#### 通道+空间

结合了通道注意力和空间注意力的优点，自适应地选择重要对象和区域

##### CBAM

<img src="https://img-blog.csdnimg.cn/f6aef21a63ca4764bb22948c90eb0a9b.png" alt="在这里插入图片描述" style="zoom:80%;" />

CBAM 包含2个独立的子模块， 通道注意力模块（Channel Attention Module，CAM) 和空间注意力模块（Spartial Attention Module，SAM) ，分别进行通道与空间上的 Attention 。 这样不只能够节约参数和计算力，并且保证了其能够做为即插即用的模块集成到现有的网络架构中去。
**Channel Attention Module（CAM）**

![在这里插入图片描述](https://img-blog.csdnimg.cn/f7701b26eb5c4416b733c45ab7012637.png)

将输入的特征图F（H×W×C）分别经过基于width和height的global max pooling（全局最大池化）和global average pooling（全局平均池化），得到两个1×1×C的特征图，接着，再将它们送入一个两层的神经网络（MLP），第一层神经元个数为 C/r（r为减少率），激活函数为 Relu，第二层神经元个数为 C，这个两层的神经网络是共享的。而后，将MLP输出的特征进行基于element-wise的加和操作，再经过sigmoid激活操作，生成最终的channel attention feature，即M_c。最后，将M_c和输入特征图F做element-wise乘法操作，生成Spatial attention模块需要的输入特征。
**Spatial Attention Module（SAM）**

![在这里插入图片描述](https://img-blog.csdnimg.cn/0de63b83001143c791401d4c758654c7.png#pic_center)

将Channel attention模块输出的特征图F‘作为本模块的输入特征图。首先做一个基于channel的global max pooling 和global average pooling，得到两个H×W×1 的特征图，然后将这2个特征图基于channel 做concat操作（通道拼接）。然后经过一个7×7卷积（7×7比3×3效果要好）操作，降维为1个channel，即H×W×1。再经过sigmoid生成spatial attention feature，即M_s。最后将该feature和该模块的输入feature做乘法，得到最终生成的特征。

##### CANet

- 通过简洁而有效的concat与特征选择机制，构件了一种新颖的连接机制；
- 在每个block内同时使用了像素级与通道级注意力机制，有助于提取更有强有力的特征；
- 通过充分实验验证了所提方法在压缩伪影移出与降噪方面的SOTA性能。

<img src="https://pic1.zhimg.com/v2-725bb04226187520a45618f122bb6d44_b.jpg" alt="img" style="zoom:50%;" />

主要目标：用于图像复原的拼接注意力网络（图像修复与去噪）

#### 空间+时间

##### STA

1. 首先随机采样视频中数量恒定的帧，接着提取图像中的特征
2. 将特征图送进时空注意力模型，为不同帧的空间区域分配注意力分数，生成二维注意分数矩阵，采用帧间正则化来限制不同帧之间的差异
3. 利用注意力分数，提取所有帧中注意力分数最高的空间区域特征图，并根据分配的注意力分数对空间区域特征图的加权和进行运算
4. 采用特征融合策略将来自不同空间区域的空间特征图连接起来，生成两组全身特征图作为全局表示和判别表示
5. 使用全局池化层和全连接层将特征图转换为向量以进行行人重识别

<img src="https://img-blog.csdnimg.cn/img_convert/5dceb83fd9e28d381a2ecadacd24cca7.png" alt="图1" style="zoom:60%;" />

