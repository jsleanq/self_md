# 多模态融合

定义：通过整合多种交流模态，包括语言、声学、视觉、触觉和生理信息，设计具有理解、推理和学习等智能能力的计算机智能体

多模态：不同存在形式或者不同信息来源，或者说对于同一个描述对象通过不同领域或者视角获取到的数据，把描述这些数据的每一个领域或者一个视角叫做一个模态

## 1.核心技术挑战

关键原则：

(1)模态是异质的，因为在不同模态中出现的信息往往表现出不同的质量、结构和表征;

(2)模态是相互联系的，因为它们经常相关、共享共性，或在用于任务推断时相互作用产生新信息

<img src="https://mmbiz.qpic.cn/mmbiz_png/AefvpgiaIPw16Mt2WDB3qoiczgSGjybPDy8o5lIddLMusgWydU18Q9iaHhYa7uEdlLhUbQS8IWVufskmTctlG2E5g/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1&retryload=1" alt="图片" style="zoom:75%;" />

### **表征**

学习反映个体模态元素之间的异质性和相互联系的表征

(1)表示融合:整合来自2个或更多模态的信息，有效减少单独表示的数量;

(2)表示协调:互换跨模态信息，目标是保持相同的表示数量，但改善多模态语境化;创建一个新的不相交的表示集，其数量通常大于输入集，反映有关内部结构的知识，如数据聚类或因子分解。 

### **对齐**

识别样式元素之间的连接和交互

(1)识别模态元素之间的连接

(2)上下文表示学习以捕获模态连接和交互

(3)处理具有歧义分割的模态输入。 

### **推理**

从多模态证据中组合知识，通常通过多个推理步骤，为特定任务开发多模态对齐和问题结构

(1)对推理发生的结构建模

(2)推理过程中的中间概念

(3)理解更抽象概念的推理范式

(4)在结构、概念和推理的研究中利用大规模的外部知识

### **生成**

反映每个模态的独特异质性和模态之间的相互联系的原始模态

(1)总结:总结多模态数据以减少信息内容，同时突出输入中最突出的部分

(2)翻译:从一种模态转换到另一种模态并保持信息内容，同时与跨模态交互保持一致

(3)创造:同时生成多个模态以增加信息内容，同时保持模态内部和跨模态的一致性

### **迁移**

在模态及其表示之间迁移知识

(1)跨模态迁移:使模型适应涉及主要模态的下游任务

(2)共同学习:通过在两种模态之间共享表示空间，将信息从次要模态转移到主要模态

### **量化**

涉及实证和理论研究，以更好地理解异质性、模态相互联系和多模态学习过程

(1)多模态数据集的异质性维度以及它们如何影响建模和学习

(2)多模态数据集和训练过的模型中模态连接和交互的存在和类型

(3)异构数据涉及的学习和优化挑战 

## 2.融合类型

### 传统融合规则

#### 早期（前）融合



#### 特征融合



#### 后融合



### 多模式融合方法

![图片](https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfrnkxTVXMrEsfcPkXd1ILxldGy2yibqQedqar82cxaVib7iaC4WbFKthlKyDZlXv8Lu3dkTG43SiaChEQ/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)

#### 强融合

##### 早期（前）融合

无论是直接将数据类型转化一致，然后concat成一体，还是LiDAR信息与Image的特征信息进行融合，还是说两者先进行特征的语义连接后成为输入，这些都是Early Fusion的操作。其实这样的输入一体化操作的好处自然是结构简便、容易部署。通过语义的提前交互，也解决了传统早期融合，模态之间语义信息交互不充分的问题。所以一定程度上，选择Early Fusion也是一个不错的选择

##### 深度（特征）融合

LiDAR点图分支和Images分支在经过各自的特征提取器后，得到高维度的特征图，并通过一系列下游模块对两个分支模态进行融合。与其他的融合方式不同，深度融合有时候也会通过级联的方式对高级特征和原始特征进行融合，同时利用高级的特征信息和含有丰富物理信息的原始特征

##### 后期（后）融合

表示在每个模态中融合结果的方法。一些后融合方法其实是同时利用了LiDAR点云分支和相机图像分支的输出，并通过两种模式的结果进行最终预测。后期融合可以看作是一种利用多模态信息对最终方案进行优化的集成方法

##### 不对称融合

会对不同的分支赋予不同的特权，因此我们将融合来自一个分支的对象级信息，而来自其他分支的数据级或功能级信息的方法定义为不对称融合,不对称融合方法至少有一个分支占主导地位，其他分支只是提供辅助信息来完成最后的任务。与后期融合相比，虽然它们提取特征的过程是相似的，但不对称融合只有来自一个分支的一个提议，而后融合会融合所有的分支信息

#### 弱融合

它直接将选中的原始LiDAR信息输入到LiDAR主干中，过程中不会直接与Image的分支主干进行特征的交互，会通过一些弱连接的方式（比如loss函数）等方式进行最后的信息融合。与之前的强融合的方法比，分支的信息交互是最少的，但是同时也能够避免在交互过程中彼此的信息不对称带来的信息干扰，又或者是避免了因为单一分支的质量不过关，而影响整理整体的融合推理

### 未来发展

#### 融合方法改进

当前阻碍模态融合的最大问题：融合模型不对齐和信息丢失

因为数据样本会存在噪声，在噪声的干扰下显然是没有办法做到精准对齐的，单靠机械的手段消除机器带来的误差，不仅难度大，还要付出比较大的成本。所以我们可以看到现在的方法，除了这种严格的转化，一一对应之外，还可以利用一些周围信息作为补充以使得融合工作可以获得更好的性能

还有一些方法是采用直接的串联数据，通过赋权值的方式进行融合。但是当前的方案依旧是不太成熟，只通过像素之间的赋权值，相加这些简单的操作可能无法融合分布差异较大的数据，因此，很难弥合两种模式之间的语义差距。一些工作试图使用更精细的级联结构来融合数据并提高性能。在未来的研究中，双线性映射等机制可以融合不同特征的特征。

#### 利用多个模态的信息

一个多任务框架，一次性覆盖不同的任务

例如，车道检测可以直观地为车道间车辆的检测提供额外的帮助，同时语义分割结果可以提高目标检测性能

未来的研究可以集中在如何利用多模态数据进行自监督学习，（包括预训练、微调或对比学习）。通过实现这些最先进的机制，融合模型将导致对数据的更深入的理解，并取得更好的结果

#### 感知传感器的内在问题

不同传感器提取的原始数据具有严重的领域相关特征。不同的相机系统有不同的光学特性，成像原理也不一致。更重要的是，数据本身可能是有领域差异的，如天气、季节或位置，即使它是由相同的传感器捕获的，他们所呈现出来的影像也有着很大的出入

来自不同模式的传感器通常具有不同的分辨率。例如，激光雷达的空间密度明显低于图像。无论采用哪种投影方法，都没有办法找到一一对应关系，所以常规的操作会剔除一些信息。无论是由于特征向量的分辨率不同还是原始信息的不平衡，都可能会导致弱化了一边模态分支的信息量，或者说是存在感。

未来的工作可以探索一种与不同空间分辨率的传感器兼容的数据方式。
