# 高性能架构之道

## 一、高性能架构

### 1.软件质量（8）

效率、功能、兼容、可移植、安全、可靠、易用、可维护

**高性能** ：在效率和可靠性上表现较好（吞吐量TPS、QPS+并发数+平均响应时间+可靠性指标：平均无故障时间）

​			效率：时间效率、容量、资源利用率

​			可靠性：成熟度、可用性、容错性、可恢复性

##二、分流设计

### 1.内容分发网络（CDN）

静态资源（图像、视频等）布置在网络的多个位置（CDN节点），核心系统布置在一个位置便于维护（源站）

**分发原理**：基于DNS完成CDN节点到源站的请求拦截

- 用户给出ip地址，LocalDNS服务器将ip发送给CDN服务商的DNS服务器，返回CDN节点ip，用户再通过CDN节点访问请求资源（计网细节），最终客户以为访问的是源站，但实际上先访问CDN节点，如果请求资源没有缓存，再将请求发送至源站

### 2.多地址直连

将内容分发过程简化为**“ 请求服务+地址获取 ”**

用户、注册中心、服务节点（用例代表：Dubbo）

- 用户每一次的请求服务都需要访问注册中心，

### 3.反向代理

对外呈现一个ip地址，但实际上分发给多个服务器（正向代理：所有请求由一个代理服务器发给内部）

反向代理层级（OSI七层模型：物理、数据链路、网络、传输（TCP/UDP）、会话、表示、应用（HTTP/FTP））

- 四层反向：IP和端口进行转发（实现简单、效率高）
- 七层反向：根据HTTP/FTP请求的具体内容转发（信息多，转发智能）——Nginx

**Nginx搭建反向代理**

主要使用upstream模块（主要是指后方服务节点），将请求按照某种策略转发给后方服务节点

- 轮询
- 加权轮询
- 请求源IP地址哈希

可以在nginx.conf文件中完成配置，也可以嵌入脚本完成相应功能

## 三、服务并行设计

请求分流（外部）到达系统后，多个节点服务同一个请求（内部）

并行（一定是同时进行）、并发（宏观同时，微观有先后顺序）

### 1.集群系统

一个系统布置多个相同节点（配置相同、执行相同任务）

#### 1.1无状态节点集群

节点给出的结果与该节点之前收到请求无关，让系统满足无状态条件，只能选用恒等类接口（查询类）

存在问题：协作问题（并行唤醒）

#### 1.2单一服务节点集群

单一服务节点集群保证从用户角度而言是一个节点，实际上可能多个用户对应一个节点（游戏服务器选择）

- 节点之间隔离，但节点配置、服务相同
- 节点保存用户的上下文信息（状态）

存在问题：节点隔离，导致出现问题用户信息丢失，容错性差

#### 1.3信息共享节点集群

单一节点集群扩容，多个服务节点共享信息池（数据库），每个节点都能读取到用户上下文信息

协作问题可以采用分布式锁的方法解决。

存在问题：受到信息池容量和读写性能的影响

#### 1.4信息一致的节点集群

每一个节点拥有自己的信息池，但是需要保证每一个节点信息池的信息同步（适用于读多写少的场景）

**与分布式系统不同，分布式系统每个节点是异构的，从属于不同模块，这里的节点是同构的，只是分担高并发的压力**

存在问题：分布式一致问题（信息池同步存在时间差）

解决方法：

- 线性一致性：两阶段提交、三阶段提交（造成每个节点吞吐量影响大）
- 最终一致性：异步消息中心（造成集群出现读写不一致）

### 2.分布式系统

将单体应用拆分成多个子应用，提升系统的压力承载能力

拆分方法：优先对大的单体应用进行拆分，成为分布式系统，当分布式系统拆分导致并发过高造成性能瓶颈时，再将并发过高的子应用部署成集群系统

存在问题：分布式一致问题（信息池同步存在时间差）

解决方法：

- 线性一致性：两阶段提交、三阶段提交（造成每个节点吞吐量影响大）
- 最终一致性：异步消息中心（造成集群出现读写不一致）

### 3.微服务系统

分布式系统中子应用和应用间存在严格的从属关系，造成性能浪费

微服务系统：每个微服务可以独立提供功能，也可以自由组合后对外提供服务，高内聚，低耦合，提升系统成熟度

存在问题：复杂度高、运维复杂、通信时延（RPC框架）

## 四、运算并发

### 1.多进程

程序如果是多进程，则多进程运算可能并行可能并发；单核CPU只能并发，多核CPU调度可并行可并发

进程是资源分配的最小单位，独立地址空间（Linux中进程切换：内核态-地址空间切换-寄存器-计数器-线程栈-用户态，原来缓存的旧数据失效，重新预热）

优势：隔离性强（不影响其他进程）

### 2.多线程

一个进程内部，一般有一个或多个线程，线程共享内存，因此线程间切换效率更高

#### 2.1线程状态及切换

新建、可运行、运行中（占用CPU资源）、阻塞（等待阻塞、同步阻塞、其他阻塞）、结束

#### 2.2.线程应用场景

1.提升效率；2.实现异步操作

#### 2.3线程池

线程提供线程回收利用的途径（实现方法：Executor类）

操作：

1. 创建线程池
2. 提交任务，线程池自动分配线程并发完成任务
3. 关闭线程池

#### 2.4多线程资源协作（以Java为例）

1. 内存模型：将Java内存分为主内存（线程共享）和工作内存（线程独享）
2. 禁止并发修改：临界区的使用（给主内存加排他锁）
3. 线程安全对象：Java内置的线程安全对象（原子对象）
4. 线程独享资源：ThreadLocal包装对象属于线程独有（空间换时间）注意**线程池回收时不改变ThreadLocal，因此重新使用时可能包含上次的数据，需要初始化**

#### 2.5多线程进度协作

- 分总式同步：等多个线程中最慢的完成才触发下一动作
- 栅栏式同步：当线程数达到一定数目时，才能一起跨过栅栏继续运行
- 总分总式同步：主任务-》子任务123-》主任务，充分利用CPU多核性
- 信号量：维护许可，线程请求许可再运行，可以灵活调度多线程

### 3.多协程

CPU中存在多个方法，一个方法被阻塞，调用另一个方法去执行（效率高）

### 4.总结

- 利用多核性能且资源完全隔离，使用多进程
- 利用多核性能不需要资源完全隔离，使用多线程
- 充分利用CPU性能，使用多协程

## 五、输入输出设计

同步与异步：针对调用方和被调用方的消息通信机制，同步：一直等回应，异步：立刻回应，好了再通知

阻塞与非阻塞：调用方调用操作到得到回应前的状态，阻塞：调用操作后被挂起（睡着了），非阻塞：调用操作后处于活跃状态（干其他事情）

### 1.IO模型

面向缓存的IO模型，存在数据接收、数据复制两个阶段

#### 1.1阻塞式IO模型（BIO）

同步、阻塞

调用方调用IO操作后被挂起，数据接收、复制完成后，调用方被唤醒

编程简单，语句返回时，读写操作完成，适用于输入输出操作较少的情况

#### 1.2非阻塞式IO模型

同步、非阻塞

数据接收阶段非阻塞（不断轮询）直到接收完成进入复制阶段，较少使用

#### 1.3信号驱动式IO模型

监听阶段异步、非阻塞

调用方监听的IO操作完成后，通知调用方触发IO操作，较少使用

#### 1.4复用式IO模型（NIO）

监听同步、阻塞

利用监听函数，监听多个IO操作（阻塞），一个调用方监听和处理多个IO操作（比BIO的优势）

#### 1.5异步式IO模型（AIO）

异步、非阻塞

减少了监听函数通知调用方的过程，直接由监听函数自动触发IO操作，完成后再通知调用方

## 六、数据库设计优化

//MySql.md

## 七、缓存设计

应用场景：1.读多写少；2.查询时间较长的场景；

提高缓存收益：

- 减少缓存键的生成时间
- 减少缓存键的检索时间
- 减少缓存内容转换时间
- 提高缓存内容的命中率

###1.缓存键值

键的生成：无碰撞（哈希算法）、高效生成、高效比较（MyBatis的CacheKey类）

值的存储：序列数据（写入缓存前序列化，取出前反序列化）、对象数据（创建map作为缓存）

**常见问题：**重复引用（甲修改了缓存数据，乙读到修改后的数据，但数据库数据可能没改）

###2.缓存更新

####2.1时效性更新

被动更新，放弃了实时一致性，转为最终一致性

缓存提供读，写数据直接写入提供方，更新清空后再从提供方备份（引发读写不一致）

实时性要求不高场景使用

#### 2.2主动更新

**Cache Aside机制：**读数据正常读，写数据先写入提供方，之后删除缓存中数据备份（顺序重要）

**Read/Write Through机制：**避免缓存不一致，读写直接对缓存操作，再由缓存写入提供方（要求缓存可靠）

**Write Behind机制：**缓存同步写入影响性能，换成异步操作，但容易造成更新丢失

### 3.缓存清理

假设：如果一条数据被访问，接下来还会被继续访问

####3.1时效式清理

到达生存时间时，自动清理，简单易用

无法限定空间，短时间内出现密集查询时，缓存空间急剧增大

#### 3.2数目阈值式清理

限制数据数目，从而限定空间

**FIFO策略**

先进先出（定长队列）

**LRU策略**

近期最少使用（少用的先清理）排序树或者链表

####3.3非强引用式清理

空间充足，占据更多空间，节约时间；空间紧张，减少占用（弹性缓存空间）

JVM（强引用、软引用、弱引用、虚引用）利用可达性分析法找出垃圾对象（软引用、弱引用）回收

### 4.缓存风险

- 缓存穿透：缓存和提供方都没有数据，调用方一直调用查询（空值备份）
- 缓存雪崩：缓存突然失效，大量请求直作用于提供方（时效清理添加随机时间、非强引用+LRU策略）
- 缓存击穿：缓存中的高频访问数据突然失效，访问直接作用于提供方（修改清理机制）
- 缓存预热：除了Read/Write Through和Write Behind机制，其他机制均存在预热问题，即数据较少命中率低（避免突然给缓存接入大量请求）

### 5.缓存位置

只要能够带来收益，可以存在在系统中的任何位置（越前收益越高）

#### 5.1客户端缓存

在客户端中设置缓存，减轻服务端压力，根据客户端类型选择不同的客户端缓存

####5.2静态缓存

后端给出的静态数据的缓存，适合缓存与用户无关的元素、页面等通用性强的数据

#### 5.3服务缓存

根据不同服务模块的运行结果进行缓存（动态结果生成过程）

#### 5.4数据库缓存

数据库本身属于服务缓存，但因为有IO、检索等过程，因此也可以设计数据库缓存

### 6.写缓存

服务调用写缓存，一般由数据处理方从写缓存中提取数据，而非写缓存主动向处理方写入（避免负载过大，异步处理）

## 八、可靠性

##九、应用保护

## 十、前端高性能

## 十一、架构设计理论

##十二、高性能架构实践

